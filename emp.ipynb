import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
data=pd.read_excel("/content/employee_burnout_analysis-AI.xlsx")
data.head()
data.shape
data.columns.values
data.info()
data.dtypes
data.describe()
data.isna().sum().any()
data.isna().sum()
data.corr(numeric_only=True)['Burn Rate'][:-1]
data['Resource Allocation'].fillna(data['Resource Allocation'].mode()[0], inplace=True)
data['Mental Fatigue Score'].fillna(data['Mental Fatigue Score'].mode()[0], inplace=True)
data['Burn Rate'].fillna(data['Burn Rate'].mode()[0], inplace=True)
data.isna().sum()
print(data['Employee ID'].value_counts())
print(data['Date of Joining'].value_counts())
print(data['Gender'].value_counts())
print(data['Company Type'].value_counts())
print(data['WFH Setup Available'].value_counts())
print(data['Designation'].value_counts())
print(data['Resource Allocation'].value_counts())
print(data['Mental Fatigue Score'].value_counts())
print(data['Burn Rate'].value_counts())
data.nunique()
sns.pairplot(data)
plt.show()
data.hist(figsize=(10,10),color='#11E8E8')
plt.show()
import seaborn as sns
import matplotlib.pyplot as plt

# Assuming 'data' is your DataFrame containing 'Gender' column
sns.countplot(x='Gender', data=data,color='#FF5733')
plt.title('Count of Employees by Gender')
plt.show()
sns.countplot(x='Company Type', data=data,color='#1114E8')
plt.title('Count of Service or product by Company Type')
plt.show()
# WFH = (Work from Home)
sns.countplot(x='WFH Setup Available', data=data,color='#E811E5')
plt.title('Count of WFH Available For Employees')
plt.show()
# designation of an employee refers to the job title or position held by the employee within an organization.
sns.countplot(x='Designation', data=data,color='#11E898')
plt.title('Count of Designation level of an Employees')
plt.show()
# The term "Mental Fatigue Score" typically refers to a quantitative measure or
# rating that assesses the level of mental tiredness or exhaustion experienced by an individual.
sns.countplot(x='Mental Fatigue Score', data=data,color='#E6FF33')
plt.title('Count of Mental Fatigue Score of an employee')
plt.show()
# "Burn Rate" can refer to the rate at which the body burns calories during physical activity.
sns.countplot(x='Burn Rate', data=data,color='#FF5733')
plt.title('Count of Burn Rate for an employee')
plt.show()
#we are removing one of the colum from edution to reducary we need remove education because machine canoot recogonice all the
#catogriacal values into numerical values for machine learning
#redundant info to remove
data=data.drop(columns=['Resource Allocation'])
data
# Identify columns with non-numeric data
non_numeric_columns = data.select_dtypes(include=['object']).columns
print(non_numeric_columns)
from sklearn.preprocessing import LabelEncoder, OneHotEncoder

# Example: Label Encoding for binary categorical data
label_encoders = {}
for column in non_numeric_columns:
    le = LabelEncoder()
    data[column] = le.fit_transform(data[column])
    label_encoders[column] = le

# Example: One-Hot Encoding for multi-class categorical data
# Uncomment the following line if you have multi-class categorical columns
# data = pd.get_dummies(data, columns=non_numeric_columns)
data
# Identify columns with non-numeric data
non_numeric_columns = data.select_dtypes(include=['object', 'datetime64']).columns
print(non_numeric_columns)
# Convert datetime columns to numeric
for column in data.select_dtypes(include=['datetime64']).columns:
    data[f'{column}_year'] = data[column].dt.year
    data[f'{column}_month'] = data[column].dt.month
    data[f'{column}_day'] = data[column].dt.day
    data = data.drop(columns=[column])
data
# Plot the heatmap
plt.figure(figsize=(12,12))
sns.heatmap(data.corr(), annot=True, cmap='PuBu')
plt.title('Correlation Plot of Numeric Columns in  Dataset')
plt.show()
import matplotlib.pyplot as plt # visualization technic to undrestand data set
plt.boxplot(data['Employee ID']) #numerical values
plt.show()
import matplotlib.pyplot as plt # visualization technic to undrestand data set
plt.boxplot(data['Gender']) #numerical values
plt.show()
plt.boxplot(data['Company Type']) #numerical values
plt.show()
plt.boxplot(data['Designation']) #numerical values
plt.show()
plt.boxplot(data['Date of Joining_month']) #numerical values
plt.show()
# we have 8 columns input and output
#feed my machine -- input and output separatly
#soo now i have to do
#7 columns as input
#income column as out put
x=data.drop(columns=['Burn Rate']) # input
x
y=data['Burn Rate'] #output
y
data
if y.dtype.kind in 'fc':
    y = pd.cut(y, bins=2, labels=[0, 1])
    from sklearn.model_selection import train_test_split #training and testing 80-20
xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=23,stratify=y)
xtrain
ytrain
from sklearn.neighbors import KNeighborsClassifier
# Create an instance of KNeighborsClassifier
knn = KNeighborsClassifier()
# Fit the model using the training data
knn.fit(xtrain, ytrain)
#training dataset
predict1=knn.predict(xtest)  #testing input
predict1
from sklearn.metrics import accuracy_score
accuracy_score(ytest,predict1) #actual ouput vs predicted o/p
from sklearn.neural_network import MLPClassifier #image dataset - cnn
clf=MLPClassifier(solver='adam',alpha=1e-5,hidden_layer_sizes=(5,2),random_state=1,max_iter=3000)
clf.fit(xtrain,ytrain)
predict2=clf.predict(xtest)  #testing input
predict2
from sklearn.metrics import accuracy_score
accuracy_score(ytest,predict2) #actual ouput vs predicted o/p
#creating model set prdection process or binary cllassification process
# regression is to
from sklearn.linear_model import LogisticRegression
lr=LogisticRegression()
lr.fit(xtrain,ytrain)
predict3=lr.predict(xtest)
predict3
from sklearn.metrics import accuracy_score
accuracy_score(ytest,predict3) #actual ouput vs predicted o/p
